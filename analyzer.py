# –≤ –Ω–∞—á–∞–ª–µ analyzer.py
# from PIL import ImageFile
# ImageFile.LOAD_TRUNCATED_IMAGES = True

import os
import shutil
import threading
import time
import urllib.request
import zipfile
from concurrent.futures import ThreadPoolExecutor, as_completed

import keras
import tensorflow as tf
from tensorflow.keras.applications.mobilenet_v2 import decode_predictions

from utils import get_cpu_cores, log_message

model_lock = threading.Lock()


# ---------------------- –û–°–ù–û–í–ù–û–ô –ê–ù–ê–õ–ò–ó ----------------------
def analyze_images2(self):
    # üö´ –ë–ª–æ–∫–∏—Ä—É–µ–º –≤—ã–±–æ—Ä —Ñ–∏–ª—å—Ç—Ä–∞, –ø–æ—Ä–æ–≥–∞ –∏ –º–æ–¥–µ–ª–∏
    self.filter_combobox.config(state="disabled")
    self.threshold_slider.config(state="disabled")
    self.model_combobox.config(state="disabled")

    threshold = self.threshold_slider.get()
    items = self.result_tree.get_children()
    total_items = len(items)
    processed_count = 0
    max_threads = min(16, get_cpu_cores())  # ‚úÖ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞

    # ‚úÖ –ù–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    start_total = time.time()

    log_message(f"‚ñ∂ –î–æ—Å—Ç—É–ø–Ω–æ —è–¥–µ—Ä: {get_cpu_cores()} | –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫–æ–≤: {max_threads}\n", self.log_console)

    self.progress["value"] = 0
    self.progress["maximum"] = total_items
    self.progress.update()

    def process_item(item):
        nonlocal processed_count
        if self.stop_analysis or not self.running:
            return
        try:
            img_path = self.result_tree.item(item)['values'][2]
            start_time = time.time()  # –Ω–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
            # score, is_nude = is_nude_image(self, img_path, threshold)
            score, is_nude, bad_flag = is_nude_image(self, img_path, threshold)
            elapsed = (time.time() - start_time) * 1000.0  # –º—Å

            if bad_flag == "BAD":
                self.image_queue.put((
                    "update_item", item,
                    {
                        "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                        "–°—Ç–∞—Ç—É—Å": "BAD",
                        "tag": "bad"
                    }
                ))
                return

            # —Ç–µ–ø–µ—Ä—å –≤ –ª–æ–≥ —Å—Ä–∞–∑—É –ø–∏—à–µ–º –∏ –≤—Ä–µ–º—è, –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.image_queue.put((
                "update_item", item,
                {
                    "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                    "–°—Ç–∞—Ç—É—Å": "‚úì" if is_nude else "‚úó",
                    "tag": "nude" if is_nude else "safe"
                }
            ))

            self.image_queue.put((
                "log",
                f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | "
                f"{score:.4f} ‚Äî {'–ù–Æ' if is_nude else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"
            ))

        except Exception as e:
            self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))

        processed_count += 1
        self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
        self.image_queue.put(("progress", processed_count))

    # ‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        future_to_item = {executor.submit(process_item, item): item for item in items}
        for future in as_completed(future_to_item):
            if self.stop_analysis or not self.running:
                break
            result = future.result()
            if result is None:
                continue

            if result[0] == "error":
                _, img_path, e = result
                self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))
            else:
                item, img_path, score, is_nude = result
                self.image_queue.put((
                    "update_item", item,
                    {
                        "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                        "–°—Ç–∞—Ç—É—Å": "‚úì" if is_nude else "‚úó",
                        "tag": "nude" if is_nude else "safe"
                    }
                ))
                self.image_queue.put(
                    ("log", f"{os.path.basename(img_path)}: {score:.4f} ‚Äî {'–ù–Æ' if is_nude else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"))

            processed_count += 1
            self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
            self.image_queue.put(("progress", processed_count))

    # ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    nude_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úì")
    safe_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úó")
    bad_count = sum(1 for f in self.all_files if str(f[6]).strip().upper() == "BAD")
    total = len(self.all_files)

    total_elapsed = (time.time() - start_total)
    report = (
        "\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞\n"
        f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n"
        f"‚îÇ –í—Å–µ–≥–æ            ‚îÇ {total:<10}‚îÇ\n"
        f"‚îÇ –ù–Æ               ‚îÇ {nude_count:<10}‚îÇ\n"
        f"‚îÇ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ       ‚îÇ {safe_count:<10}‚îÇ\n"
        f"‚îÇ BAD              ‚îÇ {bad_count:<10}‚îÇ\n"
        f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {total_elapsed:.2f} —Å–µ–∫—É–Ω–¥\n"
    )
    self.image_queue.put(("log", report))
    self.image_queue.put(("status", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"))
    self.image_queue.put(("analysis_complete", ""))

    # ‚úÖ –†–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä, –ø–æ—Ä–æ–≥ –∏ –º–æ–¥–µ–ª—å
    self.filter_combobox.config(state="readonly")  # –∏–ª–∏ state="normal", –µ—Å–ª–∏ —Ç–∞–∫ –±—ã–ª–æ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ
    self.threshold_slider.config(state="normal")
    self.model_combobox.config(state="readonly")  # –µ—Å–ª–∏ —ç—Ç–æ Combobox

def analyze_images3(self):
    # üö´ –ë–ª–æ–∫–∏—Ä—É–µ–º –≤—ã–±–æ—Ä —Ñ–∏–ª—å—Ç—Ä–∞, –ø–æ—Ä–æ–≥–∞ –∏ –º–æ–¥–µ–ª–∏
    self.filter_combobox.config(state="disabled")
    self.threshold_slider.config(state="disabled")
    self.model_combobox.config(state="disabled")

    threshold = self.threshold_slider.get()
    items = self.result_tree.get_children()
    total_items = len(items)
    processed_count = 0
    max_threads = min(16, get_cpu_cores())

    start_total = time.time()
    log_message(f"‚ñ∂ –î–æ—Å—Ç—É–ø–Ω–æ —è–¥–µ—Ä: {get_cpu_cores()} | –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫–æ–≤: {max_threads}\n", self.log_console)

    self.progress["value"] = 0
    self.progress["maximum"] = total_items
    self.progress.update()

    is_mobilenet = "mobilenet" in self.model_type.get().lower()

    def process_item(item):
        nonlocal processed_count
        if self.stop_analysis or not self.running:
            return
        try:
            img_path = self.result_tree.item(item)['values'][2]
            start_time = time.time()
            score, result, bad_flag = is_nude_image(self, img_path, threshold)
            elapsed = (time.time() - start_time) * 1000.0  # –º—Å

            if bad_flag == "BAD":
                self.image_queue.put((
                    "update_item", item,
                    {"–ü–æ—Ä–æ–≥": f"{score:.4f}", "–°—Ç–∞—Ç—É—Å": "BAD", "tag": "bad"}
                ))
                self.image_queue.put((
                    "log",
                    f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | BAD\n"
                ))
            else:
                if is_mobilenet:
                    # result = label
                    self.image_queue.put((
                        "update_item", item,
                        {"–ü–æ—Ä–æ–≥": f"{score:.4f}", "–°—Ç–∞—Ç—É—Å": result, "tag": "mobilenet"}
                    ))
                    self.image_queue.put((
                        "log",
                        f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | {score:.4f} ‚Äî {result}\n"
                    ))
                else:
                    # result = is_nude (bool)
                    self.image_queue.put((
                        "update_item", item,
                        {
                            "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                            "–°—Ç–∞—Ç—É—Å": "‚úì" if result else "‚úó",
                            "tag": "nude" if result else "safe"
                        }
                    ))
                    self.image_queue.put((
                        "log",
                        f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | "
                        f"{score:.4f} ‚Äî {'–ù–Æ' if result else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"
                    ))
        except Exception as e:
            self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))

        processed_count += 1
        self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
        self.image_queue.put(("progress", processed_count))

    # ‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        futures = [executor.submit(process_item, item) for item in items]
        for _ in as_completed(futures):
            if self.stop_analysis or not self.running:
                break

    # ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    nude_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úì")
    safe_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úó")
    bad_count = sum(1 for f in self.all_files if str(f[6]).strip().upper() == "BAD")
    # –î–ª—è MobileNet –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ–±—Ä–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö label'–æ–≤ –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏
    total = len(self.all_files)

    total_elapsed = (time.time() - start_total)
    report = (
        "\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞\n"
        f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n"
        f"‚îÇ –í—Å–µ–≥–æ            ‚îÇ {total:<10}‚îÇ\n"
        f"‚îÇ –ù–Æ               ‚îÇ {nude_count:<10}‚îÇ\n"
        f"‚îÇ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ       ‚îÇ {safe_count:<10}‚îÇ\n"
        f"‚îÇ BAD              ‚îÇ {bad_count:<10}‚îÇ\n"
        f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {total_elapsed:.2f} —Å–µ–∫—É–Ω–¥\n"
    )
    self.image_queue.put(("log", report))
    self.image_queue.put(("status", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"))
    self.image_queue.put(("analysis_complete", ""))

    # ‚úÖ –†–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä, –ø–æ—Ä–æ–≥ –∏ –º–æ–¥–µ–ª—å
    self.filter_combobox.config(state="readonly")
    self.threshold_slider.config(state="normal")
    self.model_combobox.config(state="readonly")

def analyze_images(self):
    # üö´ –ë–ª–æ–∫–∏—Ä—É–µ–º –≤—ã–±–æ—Ä —Ñ–∏–ª—å—Ç—Ä–∞, –ø–æ—Ä–æ–≥–∞ –∏ –º–æ–¥–µ–ª–∏
    self.filter_combobox.config(state="disabled")
    self.threshold_slider.config(state="disabled")
    self.model_combobox.config(state="disabled")

    threshold = self.threshold_slider.get()
    items = self.result_tree.get_children()
    total_items = len(items)
    processed_count = 0
    max_threads = min(16, get_cpu_cores())

    start_total = time.time()
    log_message(f"‚ñ∂ –î–æ—Å—Ç—É–ø–Ω–æ —è–¥–µ—Ä: {get_cpu_cores()} | –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫–æ–≤: {max_threads}\n", self.log_console)

    self.progress["value"] = 0
    self.progress["maximum"] = total_items
    self.progress.update()

    model_name = self.model_type.get().lower()
    is_mobilenet = "mobilenet" in model_name
    is_gantman = "gantman" in model_name

    def process_item(item):
        nonlocal processed_count
        if self.stop_analysis or not self.running:
            return
        try:
            img_path = self.result_tree.item(item)['values'][2]
            start_time = time.time()
            score, result, bad_flag = is_nude_image(self, img_path, threshold)
            elapsed = (time.time() - start_time) * 1000.0  # –º—Å

            # BAD —Ñ–∞–π–ª—ã
            if bad_flag == "BAD":
                self.image_queue.put((
                    "update_item", item,
                    {"–ü–æ—Ä–æ–≥": f"{score:.4f}", "–°—Ç–∞—Ç—É—Å": "BAD", "tag": "bad"}
                ))
                self.image_queue.put((
                    "log",
                    f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | BAD\n"
                ))
            else:
                # MobileNetV2: result ‚Äî label
                if is_mobilenet:
                    self.image_queue.put((
                        "update_item", item,
                        {"–ü–æ—Ä–æ–≥": f"{score:.4f}", "–°—Ç–∞—Ç—É—Å": result, "tag": "mobilenet"}
                    ))
                    self.image_queue.put((
                        "log",
                        f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | {score:.4f} ‚Äî {result}\n"
                    ))
                # GantMan: result ‚Äî label (drawings, hentai, neutral, porn, sexy)
                elif is_gantman:
                    self.image_queue.put((
                        "update_item", item,
                        {"–ü–æ—Ä–æ–≥": f"{score:.4f}", "–°—Ç–∞—Ç—É—Å": result, "tag": "mobilenet"}  # –º–æ–∂–Ω–æ –∑–∞–≤–µ—Å—Ç–∏ —Å–≤–æ–π tag
                    ))
                    self.image_queue.put((
                        "log",
                        f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | {score:.4f} ‚Äî {result}\n"
                    ))
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ NSFW –º–æ–¥–µ–ª–∏: result ‚Äî bool
                else:
                    self.image_queue.put((
                        "update_item", item,
                        {
                            "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                            "–°—Ç–∞—Ç—É—Å": "‚úì" if result else "‚úó",
                            "tag": "nude" if result else "safe"
                        }
                    ))
                    self.image_queue.put((
                        "log",
                        f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | "
                        f"{score:.4f} ‚Äî {'–ù–Æ' if result else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"
                    ))

        except Exception as e:
            self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))

        processed_count += 1
        self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
        self.image_queue.put(("progress", processed_count))

    # ‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        futures = [executor.submit(process_item, item) for item in items]
        for _ in as_completed(futures):
            if self.stop_analysis or not self.running:
                break

    # ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    nude_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úì")
    safe_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úó")
    bad_count = sum(1 for f in self.all_files if str(f[6]).strip().upper() == "BAD")
    total = len(self.all_files)

    total_elapsed = (time.time() - start_total)
    report = (
        "\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞\n"
        f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n"
        f"‚îÇ –í—Å–µ–≥–æ            ‚îÇ {total:<10}‚îÇ\n"
        f"‚îÇ –ù–Æ               ‚îÇ {nude_count:<10}‚îÇ\n"
        f"‚îÇ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ       ‚îÇ {safe_count:<10}‚îÇ\n"
        f"‚îÇ BAD              ‚îÇ {bad_count:<10}‚îÇ\n"
        f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {total_elapsed:.2f} —Å–µ–∫—É–Ω–¥\n"
    )
    self.image_queue.put(("log", report))
    self.image_queue.put(("status", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"))
    self.image_queue.put(("analysis_complete", ""))

    # ‚úÖ –†–∞–∑–±–ª–æ–∫–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä, –ø–æ—Ä–æ–≥ –∏ –º–æ–¥–µ–ª—å
    self.filter_combobox.config(state="readonly")
    self.threshold_slider.config(state="normal")
    self.model_combobox.config(state="readonly")



# ---------------------- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô ----------------------
def initialize_model(self):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    # ‚úÖ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –º–æ–¥–µ–ª–∏
    self.model = None
    self.predict_fn = None
    self.model_name = self.model_type.get().lower()

    log_message(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏: {self.model_name}\n", self.log_console)

    try:
        if "yahoo" in self.model_name:
            import opennsfw2
            self.model = opennsfw2
            self.predict_fn = lambda path: float(self.model.predict_image(path))
            log_message("[Yahoo] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        elif "mobilenet" in self.model_name:
            from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
            log_message("[MobileNetV2] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
            self.model = tf.keras.applications.MobileNetV2(weights='imagenet')
            self.preprocess_input = preprocess_input

            def mobilenet_predict2(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = self.preprocess_input(img)
                img = tf.expand_dims(img, axis=0)
                predictions = self.model.predict(img)
                return float(predictions[0][0])

            def mobilenet_predict(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = self.preprocess_input(img)
                img = tf.expand_dims(img, axis=0)
                predictions = self.model.predict(img)
                decoded = decode_predictions(predictions, top=1)[0]  # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø‚Äë1
                top_id, label, prob = decoded[0]
                # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º label –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                return label, float(prob)


            self.predict_fn = mobilenet_predict
            log_message("[MobileNetV2] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        elif "nsfw hub" in self.model_name:
            import tensorflow_hub as hub
            log_message("[NSFW Hub] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
            self.model = hub.load("https://tfhub.dev/GourmetAI/nsfw_classifier/1")

            def nsfw_hub_predict(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = tf.cast(img, tf.float32) / 255.0
                img = tf.expand_dims(img, axis=0)
                preds = self.model(img).numpy()[0]
                return max(preds[1], preds[3], preds[4])

            self.predict_fn = nsfw_hub_predict
            log_message("[NSFW Hub] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        elif "gantman" in self.model_name:
            log_message("[GantMan] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...\n", self.log_console)
            initialize_model_gantman(self)

        elif "tf hub" in self.model_name:
            import tensorflow_hub as hub
            if not hasattr(self, 'model') or self.model is None:
                log_message("[TF Hub] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
                self.model = hub.load("https://tfhub.dev/google/openimages/v4/ssd/mobilenetv2/classification/4")

            def tfhub_predict(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = tf.expand_dims(img, axis=0)
                return float(self.model(img).numpy()[0][1])

            self.predict_fn = tfhub_predict
            log_message("[TF Hub] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        else:
            log_message(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {self.model_name}\n", self.log_console)
            self.model = None
            self.predict_fn = None

    except Exception as e:
        log_message(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}\n", self.log_console)
        raise


def initialize_model_gantman(self):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç GantMan NSFW –º–æ–¥–µ–ª—å"""
    model_dir = "nsfw_model_mobilenet_v2"
    saved_model_path = os.path.join(model_dir, "mobilenet_v2_140_224")
    zip_path = "nsfw_model.zip"

    if not hasattr(self, "model_lock"):
        self.model_lock = threading.Lock()

    with self.model_lock:
        if not os.path.exists(saved_model_path):
            os.makedirs(model_dir, exist_ok=True)
            if not os.path.exists(zip_path):
                log_message("[GantMan] –°–∫–∞—á–∏–≤–∞–µ–º NSFW –º–æ–¥–µ–ª—å (~90MB)...\n", self.log_console)
                urllib.request.urlretrieve(
                    "https://github.com/GantMan/nsfw_model/archive/refs/heads/master.zip",
                    zip_path
                )
            log_message("[GantMan] –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
            tmp_dir = "gantman_tmp"
            if os.path.exists(tmp_dir):
                shutil.rmtree(tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(tmp_dir)
            shutil.move(os.path.join(tmp_dir, "nsfw_model-master", "mobilenet_v2_140_224"), saved_model_path)
            shutil.rmtree(tmp_dir)

        log_message(f"[GantMan] –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ {saved_model_path}...\n", self.log_console)
        self.model = keras.layers.TFSMLayer(saved_model_path, call_endpoint='serving_default')
        self.predict_fn = lambda path: predict_gantman(self, path)
        log_message("‚úÖ [GantMan] –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)


# ---------------------- PREDICT –§–£–ù–ö–¶–ò–ò ----------------------
def predict_gantman2(self, img_path: str) -> float:
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [224, 224])
    img = tf.cast(img, tf.float32) / 255.0
    img = tf.expand_dims(img, 0)
    outputs = self.model(img)
    if isinstance(outputs, dict):
        scores = list(outputs.values())[0].numpy()[0]
    else:
        scores = outputs.numpy()[0]
    return float(max(scores[1], scores[3], scores[4]))

import numpy as np

def predict_gantman(self, img_path: str):
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [224, 224])
    img = tf.cast(img, tf.float32) / 255.0
    img = tf.expand_dims(img, 0)

    outputs = self.model(img)
    if isinstance(outputs, dict):
        scores = list(outputs.values())[0].numpy()[0]
    else:
        scores = outputs.numpy()[0]

    labels = ["drawings", "hentai", "neutral", "porn", "sexy"]
    best_idx = int(np.argmax(scores))
    best_label = labels[best_idx]
    best_score = float(scores[best_idx])

    return best_score, best_label


# ---------------------- –û–°–ù–û–í–ù–û–ô –í–´–ó–û–í ----------------------
def is_nude_image2(self, img_path: str, threshold: float):
    try:
        current_name = self.model_type.get().lower()

        if not hasattr(self, 'predict_fn') or self.predict_fn is None:
            self.initialize_model()

        try:
            if "gantman" in current_name:
                if self.model is None:
                    self.initialize_model()
                score = predict_gantman(self, img_path)
            else:
                score = self.predict_fn(img_path)

            # –µ—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ ‚Äî –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω
            return score, score >= threshold, None  # —Ç—Ä–µ—Ç–∏–π —Ñ–ª–∞–≥ ‚Äî –Ω–µ BAD

        except OSError as ose:
            log_message(f"[SKIP] –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {img_path}: {ose}\n", self.log_console)
            return 0.0, False, "BAD"
        except Exception as inner_e:
            log_message(f"[SKIP] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {inner_e}\n", self.log_console)
            return 0.0, False, "BAD"

    except Exception as e:
        log_message(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {str(e)}\n", self.log_console)
        import traceback
        traceback.print_exc()
        return 0.0, False, "BAD"


def is_nude_image3(self, img_path: str, threshold: float):
    try:
        current_name = self.model_type.get().lower()

        if not hasattr(self, 'predict_fn') or self.predict_fn is None:
            self.initialize_model()

        # GantMan –∏ –ø—Ä–æ—á–∏–µ NSFW –º–æ–¥–µ–ª–∏:
        if "gantman" in current_name or "yahoo" in current_name or "nsfw" in current_name or "hub" in current_name:
            score = self.predict_fn(img_path)
            return score, score >= threshold, None

        # MobileNetV2: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–≥ –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        if "mobilenet" in current_name:
            label, prob = self.predict_fn(img_path)
            # –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º:
            return prob, label, None  # –≤—Ç–æ—Ä–æ–π —ç–ª–µ–º–µ–Ω—Ç ‚Äì –±—É–¥–µ—Ç —Å—Ç—Ä–æ–∫–∞ (label)

    except OSError as ose:
        log_message(f"[SKIP] –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {img_path}: {ose}\n", self.log_console)
        return 0.0, "BAD", "BAD"
    except Exception as e:
        log_message(f"[SKIP] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {e}\n", self.log_console)
        return 0.0, "BAD", "BAD"

def is_nude_image(self, img_path: str, threshold: float):
    try:
        current_name = self.model_type.get().lower()

        if not hasattr(self, 'predict_fn') or self.predict_fn is None:
            self.initialize_model()

        # GantMan
        if "gantman" in current_name:
            if self.model is None:
                self.initialize_model()
            score, label = predict_gantman(self, img_path)
            return score, label, None  # –≤–µ—Ä–Ω–µ–º —Ç–µ–≥ –≤–º–µ—Å—Ç–æ true/false

        # MobileNetV2
        if "mobilenet" in current_name:
            label, prob = self.predict_fn(img_path)
            return prob, label, None

        # –û—Å—Ç–∞–ª—å–Ω—ã–µ NSFW –º–æ–¥–µ–ª–∏ (Yahoo, NSFW Hub –∏ –¥—Ä.)
        score = self.predict_fn(img_path)
        return score, score >= threshold, None

    except OSError as ose:
        log_message(f"[SKIP] –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {img_path}: {ose}\n", self.log_console)
        return 0.0, "BAD", "BAD"
    except Exception as e:
        log_message(f"[SKIP] –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {e}\n", self.log_console)
        return 0.0, "BAD", "BAD"

