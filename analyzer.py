from PIL import Image
import numpy as np
import time  # –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –µ—â—ë –Ω–µ—Ç

import os
import urllib.request
import zipfile
import shutil
import tensorflow as tf
import keras
import threading
from concurrent.futures import ThreadPoolExecutor
from concurrent.futures import ThreadPoolExecutor, as_completed
from utils import get_cpu_cores, log_message

model_lock = threading.Lock()

# ---------------------- –û–°–ù–û–í–ù–û–ô –ê–ù–ê–õ–ò–ó ----------------------
def analyze_images2(self):
    threshold = self.threshold_slider.get()
    items = self.result_tree.get_children()
    total_items = len(items)
    processed_count = 0
    max_threads = min(16, get_cpu_cores())

    # ‚úÖ –ù–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    start_total = time.time()

    log_message(f"‚ñ∂ –î–æ—Å—Ç—É–ø–Ω–æ —è–¥–µ—Ä: {get_cpu_cores()} | –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫–æ–≤: {max_threads}\n", self.log_console)

    self.progress["value"] = 0
    self.progress["maximum"] = total_items
    self.progress.update()

    def process_item(item):
        nonlocal processed_count
        if self.stop_analysis or not self.running:
            return
        try:
            img_path = self.result_tree.item(item)['values'][2]
            score, is_nude = is_nude_image(self, img_path, threshold)
            self.image_queue.put((
                "update_item", item,
                {
                    "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                    "–ù–Æ": "‚úì" if is_nude else "‚úó",
                    "tag": "nude" if is_nude else "safe"
                }
            ))
            self.image_queue.put(("log", f"{os.path.basename(img_path)}: {score:.4f} ‚Äî {'–ù–Æ' if is_nude else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"))
        except Exception as e:
            self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))

        processed_count += 1
        self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
        self.image_queue.put(("progress", processed_count))

    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        for item in items:
            if self.stop_analysis or not self.running:
                break
            executor.submit(process_item, item)

    nude_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úì")
    safe_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úó")
    total = len(self.all_files)

    total_elapsed = (time.time() - start_total)
    report = (
        "\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞\n"
        f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n"
        f"‚îÇ –í—Å–µ–≥–æ            ‚îÇ {total:<10}‚îÇ\n"
        f"‚îÇ –ù–Æ               ‚îÇ {nude_count:<10}‚îÇ\n"
        f"‚îÇ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ       ‚îÇ {safe_count:<10}‚îÇ\n"
        f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {total_elapsed:.2f} —Å–µ–∫—É–Ω–¥\n"
    )
    self.image_queue.put(("log", report))
    self.image_queue.put(("status", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"))
    self.image_queue.put(("analysis_complete", ""))

from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import os

def analyze_images(self):
    threshold = self.threshold_slider.get()
    items = self.result_tree.get_children()
    total_items = len(items)
    processed_count = 0
    max_threads = min(16, get_cpu_cores())  # ‚úÖ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞

    # ‚úÖ –ù–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    start_total = time.time()

    log_message(f"‚ñ∂ –î–æ—Å—Ç—É–ø–Ω–æ —è–¥–µ—Ä: {get_cpu_cores()} | –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫–æ–≤: {max_threads}\n", self.log_console)

    self.progress["value"] = 0
    self.progress["maximum"] = total_items
    self.progress.update()

    def process_item2(item):
        """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Ç–æ–∫–∞"""
        if self.stop_analysis or not self.running:
            return None
        img_path = self.result_tree.item(item)['values'][2]
        try:
            score, is_nude = is_nude_image(self, img_path, threshold)
            return (item, img_path, score, is_nude)
        except Exception as e:
            return ("error", img_path, e)

    def process_item(item):
        nonlocal processed_count
        if self.stop_analysis or not self.running:
            return
        try:
            img_path = self.result_tree.item(item)['values'][2]
            start_time = time.time()  # –Ω–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
            score, is_nude = is_nude_image(self, img_path, threshold)
            elapsed = (time.time() - start_time) * 1000.0  # –º—Å

            # —Ç–µ–ø–µ—Ä—å –≤ –ª–æ–≥ —Å—Ä–∞–∑—É –ø–∏—à–µ–º –∏ –≤—Ä–µ–º—è, –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.image_queue.put((
                "update_item", item,
                {
                    "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                    "–ù–Æ": "‚úì" if is_nude else "‚úó",
                    "tag": "nude" if is_nude else "safe"
                }
            ))

            self.image_queue.put((
                "log",
                f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms | "
                f"{score:.4f} ‚Äî {'–ù–Æ' if is_nude else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"
            ))

        except Exception as e:
            self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))

        processed_count += 1
        self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
        self.image_queue.put(("progress", processed_count))

    # ‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        future_to_item = {executor.submit(process_item, item): item for item in items}
        for future in as_completed(future_to_item):
            if self.stop_analysis or not self.running:
                break
            result = future.result()
            if result is None:
                continue

            if result[0] == "error":
                _, img_path, e = result
                self.image_queue.put(("log", f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {e}\n"))
            else:
                item, img_path, score, is_nude = result
                self.image_queue.put((
                    "update_item", item,
                    {
                        "–ü–æ—Ä–æ–≥": f"{score:.4f}",
                        "–ù–Æ": "‚úì" if is_nude else "‚úó",
                        "tag": "nude" if is_nude else "safe"
                    }
                ))
                self.image_queue.put(("log", f"{os.path.basename(img_path)}: {score:.4f} ‚Äî {'–ù–Æ' if is_nude else '–±–µ–∑–æ–ø–∞—Å–Ω–æ'}\n"))

            processed_count += 1
            self.image_queue.put(("status", f"–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π... ({processed_count} / {total_items})"))
            self.image_queue.put(("progress", processed_count))

    # ‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    nude_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úì")
    safe_count = sum(1 for f in self.all_files if str(f[6]).strip() == "‚úó")
    total = len(self.all_files)

    total_elapsed = (time.time() - start_total)
    report = (
        "\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞\n"
        f"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n"
        f"‚îÇ –í—Å–µ–≥–æ            ‚îÇ {total:<10}‚îÇ\n"
        f"‚îÇ –ù–Æ               ‚îÇ {nude_count:<10}‚îÇ\n"
        f"‚îÇ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ       ‚îÇ {safe_count:<10}‚îÇ\n"
        f"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
        f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {total_elapsed:.2f} —Å–µ–∫—É–Ω–¥\n"
    )
    self.image_queue.put(("log", report))
    self.image_queue.put(("status", "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"))
    self.image_queue.put(("analysis_complete", ""))


# ---------------------- –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ï–ô ----------------------
def initialize_model(self):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    # ‚úÖ –û—á–∏—Å—Ç–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –º–æ–¥–µ–ª–∏
    self.model = None
    self.predict_fn = None
    self.model_name = self.model_type.get().lower()

    log_message(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏: {self.model_name}\n", self.log_console)

    try:
        if "yahoo" in self.model_name:
            import opennsfw2
            self.model = opennsfw2
            self.predict_fn = lambda path: float(self.model.predict_image(path))
            log_message("[Yahoo] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        elif "mobilenet" in self.model_name:
            from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
            log_message("[MobileNetV2] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
            self.model = tf.keras.applications.MobileNetV2(weights='imagenet')
            self.preprocess_input = preprocess_input
            def mobilenet_predict(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = self.preprocess_input(img)
                img = tf.expand_dims(img, axis=0)
                predictions = self.model.predict(img)
                return float(predictions[0][0])
            self.predict_fn = mobilenet_predict
            log_message("[MobileNetV2] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        elif "nsfw hub" in self.model_name:
            import tensorflow_hub as hub
            log_message("[NSFW Hub] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
            self.model = hub.load("https://tfhub.dev/GourmetAI/nsfw_classifier/1")
            def nsfw_hub_predict(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = tf.cast(img, tf.float32) / 255.0
                img = tf.expand_dims(img, axis=0)
                preds = self.model(img).numpy()[0]
                return max(preds[1], preds[3], preds[4])
            self.predict_fn = nsfw_hub_predict
            log_message("[NSFW Hub] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        elif "gantman" in self.model_name:
            log_message("[GantMan] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...\n", self.log_console)
            initialize_model_gantman(self)

        elif "tf hub" in self.model_name:
            import tensorflow_hub as hub
            if not hasattr(self, 'model') or self.model is None:
                log_message("[TF Hub] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
                self.model = hub.load("https://tfhub.dev/google/openimages/v4/ssd/mobilenetv2/classification/4")
            def tfhub_predict(img_path):
                img = tf.io.read_file(img_path)
                img = tf.image.decode_jpeg(img, channels=3)
                img = tf.image.resize(img, [224, 224])
                img = tf.expand_dims(img, axis=0)
                return float(self.model(img).numpy()[0][1])
            self.predict_fn = tfhub_predict
            log_message("[TF Hub] ‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)

        else:
            log_message(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {self.model_name}\n", self.log_console)
            self.model = None
            self.predict_fn = None

    except Exception as e:
        log_message(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}\n", self.log_console)
        raise


def initialize_model_gantman(self):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç GantMan NSFW –º–æ–¥–µ–ª—å"""
    model_dir = "nsfw_model_mobilenet_v2"
    saved_model_path = os.path.join(model_dir, "mobilenet_v2_140_224")
    zip_path = "nsfw_model.zip"

    if not hasattr(self, "model_lock"):
        self.model_lock = threading.Lock()

    with self.model_lock:
        if not os.path.exists(saved_model_path):
            os.makedirs(model_dir, exist_ok=True)
            if not os.path.exists(zip_path):
                log_message("[GantMan] –°–∫–∞—á–∏–≤–∞–µ–º NSFW –º–æ–¥–µ–ª—å (~90MB)...\n", self.log_console)
                urllib.request.urlretrieve(
                    "https://github.com/GantMan/nsfw_model/archive/refs/heads/master.zip",
                    zip_path
                )
            log_message("[GantMan] –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏...\n", self.log_console)
            tmp_dir = "gantman_tmp"
            if os.path.exists(tmp_dir):
                shutil.rmtree(tmp_dir)
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(tmp_dir)
            shutil.move(os.path.join(tmp_dir, "nsfw_model-master", "mobilenet_v2_140_224"), saved_model_path)
            shutil.rmtree(tmp_dir)

        log_message(f"[GantMan] –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ {saved_model_path}...\n", self.log_console)
        self.model = keras.layers.TFSMLayer(saved_model_path, call_endpoint='serving_default')
        self.predict_fn = lambda path: predict_gantman(self, path)
        log_message("‚úÖ [GantMan] –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ\n", self.log_console)


# ---------------------- PREDICT –§–£–ù–ö–¶–ò–ò ----------------------
def predict_gantman(self, img_path: str) -> float:
    img = tf.io.read_file(img_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, [224, 224])
    img = tf.cast(img, tf.float32) / 255.0
    img = tf.expand_dims(img, 0)
    outputs = self.model(img)
    if isinstance(outputs, dict):
        scores = list(outputs.values())[0].numpy()[0]
    else:
        scores = outputs.numpy()[0]
    return float(max(scores[1], scores[3], scores[4]))


# ---------------------- –û–°–ù–û–í–ù–û–ô –í–´–ó–û–í ----------------------
def is_nude_image(self, img_path: str, threshold: float):
    try:
        # start_time = time.time()  # ‚úÖ –Ω–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞
        current_name = self.model_type.get().lower()

        if not hasattr(self, 'predict_fn') or self.predict_fn is None:
            self.initialize_model()

        # –æ—Ç–¥–µ–ª—å–Ω–∞—è –≤–µ—Ç–∫–∞ –¥–ª—è GantMan
        if "gantman" in current_name:
        # if "gantman" in self.model_type.get().lower():
            if self.model is None:
                self.initialize_model()
            score = predict_gantman(self, img_path)
        else:
            score = self.predict_fn(img_path)

        # elapsed = (time.time() - start_time) * 1000.0  # ‚úÖ –º—Å
        # log_message(f"‚è± –û–±—Ä–∞–±–æ—Ç–∫–∞ {os.path.basename(img_path)} –∑–∞–Ω—è–ª–∞ {elapsed:.1f} ms\n", self.log_console)

        return score, score >= threshold

    except Exception as e:
        log_message(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {img_path}: {str(e)}\n", self.log_console)
        import traceback
        traceback.print_exc()
        return 0.0, False


